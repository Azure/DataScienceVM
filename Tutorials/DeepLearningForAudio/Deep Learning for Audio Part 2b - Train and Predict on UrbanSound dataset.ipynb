{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Train and predict on urbansound8k dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter Notebook, we will train and predict on UrbanSound8K dataset. There are a few published benchmarks, notebly mentioned in the papers below:\n",
    "\n",
    "- [Environmental sound classification with convolutional neural networks](http://karol.piczak.com/papers/Piczak2015-ESC-ConvNet.pdf) by Karol J Piczak.\n",
    "- [Deep convolutional neural networks and data augmentation for environmental sound classification](https://arxiv.org/abs/1608.04363) by Justin Salamon and Juan Pablo Bello\n",
    "- [Learning from Between-class Examples for Deep Sound Recognition](https://arxiv.org/abs/1711.10282) by Yuji Tokozume, Yoshitaka Ushiku, Tatsuya Harada\n",
    "\n",
    "And the third one achieves the state-of-art performance, with an error rate around 21.7. In this notebook, we will demostrate how to use Azure DSVM to achive similar performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# change the seed before anything else\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import keras\n",
    "keras.backend.clear_session()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dropout\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.optimizers import Adamax\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.regularizers import l2\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "tf.set_random_seed(20171218)\n",
    "np.random.seed(20171218)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "frames = 150\n",
    "bands = 150\n",
    "feature_size = bands * frames\n",
    "data_dir = \"/home/maxkaz/Downloads/us8k-\" + str(bands) + \"bands-\" + str(frames) + \"frames-3channel\"\n",
    "num_channels = 3\n",
    "num_labels = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're going to run this code with the full data set, this notebook assumes you've already parsed all the files and saved the numpy array to disk. We will load all the training examples (a set of 43722 examples, the first 8 folds), then use fold9 as the validation fold, and use fold 10 as the test fold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this will aggregate all the training data \n",
    "def load_all_folds(test_fold):\n",
    "    assert (type(test_fold) == int)\n",
    "    assert (test_fold > 0 and test_fold < 11)\n",
    "    subsequent_fold = False\n",
    "\n",
    "    train_set_range = list(range(1, 11))\n",
    "    train_set_range.remove(test_fold)\n",
    "    valid_fold = train_set_range.pop()\n",
    "\n",
    "    for k in train_set_range:\n",
    "        fold_name = 'fold' + str(k)\n",
    "        feature_file = os.path.join(data_dir, fold_name + '_x.npy')\n",
    "        labels_file = os.path.join(data_dir, fold_name + '_y.npy')\n",
    "        loaded_features = np.load(feature_file)\n",
    "        # flip the spectrogram for each channel\n",
    "        loaded_features = np.transpose(loaded_features, (0, 2, 1, 3))\n",
    "        loaded_labels = np.load(labels_file)\n",
    "        print(\"Adding \", fold_name, \"New Features: \", loaded_features.shape)\n",
    "\n",
    "        if subsequent_fold:\n",
    "            train_x_loaded = np.concatenate((train_x_loaded, loaded_features))\n",
    "            train_y_loaded = np.concatenate((train_y_loaded, loaded_labels))\n",
    "        else:\n",
    "            train_x_loaded = loaded_features\n",
    "            train_y_loaded = loaded_labels\n",
    "            subsequent_fold = True\n",
    "\n",
    "    # use the penultimate fold for validation\n",
    "    valid_fold_name = 'fold' + str(valid_fold)\n",
    "    feature_file = os.path.join(data_dir, valid_fold_name + '_x.npy')\n",
    "    labels_file = os.path.join(data_dir, valid_fold_name + '_y.npy')\n",
    "    valid_x = np.load(feature_file)\n",
    "    # flip the spectrogram for each channel\n",
    "    valid_x = np.transpose(valid_x, (0, 2, 1, 3))\n",
    "    valid_y = np.load(labels_file)\n",
    "\n",
    "    # and use the last fold for testing\n",
    "    test_fold_name = 'fold' + str(test_fold)\n",
    "    feature_file = os.path.join(data_dir, test_fold_name + '_x.npy')\n",
    "    labels_file = os.path.join(data_dir, test_fold_name + '_y.npy')\n",
    "    test_x = np.load(feature_file)\n",
    "    test_x = np.transpose(test_x, (0, 2, 1, 3))\n",
    "    test_y = np.load(labels_file)\n",
    "    return train_x_loaded, train_y_loaded, valid_x, valid_y, test_x, test_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Convolutional Neural Network with Keras and TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the imports we need and a few configuration variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method defines some evaluation metrics that will be used to evaluate the performance of a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_x, test_y):\n",
    "    y_prob = model.predict(test_x, verbose=0)\n",
    "    y_pred = np.argmax(y_prob, axis=-1)\n",
    "    y_true = np.argmax(test_y, 1)\n",
    "\n",
    "    # evaluate the model\n",
    "    score, accuracy = model.evaluate(test_x, test_y, batch_size=32)\n",
    "    print(\"\\nAccuracy = {:.4f}\".format(accuracy))\n",
    "    print(\"\\nError Rate = {:.4f}\".format(1. - accuracy))\n",
    "\n",
    "    # the F-score gives a similiar value to the accuracy score, but useful for cross-checking\n",
    "    p, r, f, s = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "    print(\"F-Score = {:.4f}\", f)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same DNN architecture on featurized data as the winning solution to DCASE 2016 Track 4. DCASE is the audio challenge for sound domain and is held every year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # section 1\n",
    "\n",
    "    model.add(Convolution2D(filters=32, kernel_size=5,\n",
    "                            strides=2,\n",
    "                            padding=\"same\",\n",
    "                            kernel_regularizer=l2(0.0001),\n",
    "                            kernel_initializer=\"normal\",\n",
    "                            input_shape=(frames, bands, num_channels)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Convolution2D(filters=32, kernel_size=3,\n",
    "                            strides=1,\n",
    "                            padding=\"same\",\n",
    "                            kernel_regularizer=l2(0.0001),\n",
    "                            kernel_initializer=\"normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # section 2    \n",
    "    model.add(Convolution2D(filters=64, kernel_size=3,\n",
    "                            strides=1,\n",
    "                            padding=\"same\",\n",
    "                            kernel_regularizer=l2(0.0001),\n",
    "                            kernel_initializer=\"normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Convolution2D(filters=64, kernel_size=3,\n",
    "                            strides=1,\n",
    "                            padding=\"same\",\n",
    "                            kernel_regularizer=l2(0.0001),\n",
    "                            kernel_initializer=\"normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # section 3\n",
    "    model.add(Convolution2D(filters=128, kernel_size=3,\n",
    "                            strides=1,\n",
    "                            padding=\"same\",\n",
    "                            kernel_regularizer=l2(0.0001),\n",
    "                            kernel_initializer=\"normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Convolution2D(filters=128, kernel_size=3,\n",
    "                            strides=1,\n",
    "                            padding=\"same\",\n",
    "                            kernel_regularizer=l2(0.0001),\n",
    "                            kernel_initializer=\"normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Convolution2D(filters=128, kernel_size=3,\n",
    "                            strides=1,\n",
    "                            padding=\"same\",\n",
    "                            kernel_regularizer=l2(0.0001),\n",
    "                            kernel_initializer=\"normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Convolution2D(filters=128, kernel_size=3,\n",
    "                            strides=1,\n",
    "                            padding=\"same\",\n",
    "                            kernel_regularizer=l2(0.0001),\n",
    "                            kernel_initializer=\"normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # section 4\n",
    "    model.add(Convolution2D(filters=512, kernel_size=3,\n",
    "                            strides=1,\n",
    "                            padding=\"valid\",\n",
    "                            kernel_regularizer=l2(0.0001),\n",
    "                            kernel_initializer=\"normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Convolution2D(filters=512, kernel_size=1,\n",
    "                            strides=1,\n",
    "                            padding=\"valid\",\n",
    "                            kernel_regularizer=l2(0.0001),\n",
    "                            kernel_initializer=\"normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # section 5\n",
    "    model.add(Convolution2D(filters=10, kernel_size=1,\n",
    "                            strides=1,\n",
    "                            padding=\"valid\",\n",
    "                            kernel_regularizer=l2(0.0001),\n",
    "                            kernel_initializer=\"normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # compile and fit model, reduce epochs if you want a result faster\n",
    "    # the validation set is used to identify parameter settings (epoch) that achieves \n",
    "    # the highest classification accuracy\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply scaling factor to a dataset - train, validation or test\n",
    "def do_scale(x4d, verbose = True):\n",
    "    \"\"\"Do scale on the input sequence data.\n",
    "\n",
    "    Args:\n",
    "      x34d: ndarray, input sequence data, shape: (n_clips, n_time, n_freq, channel)      \n",
    "      verbose: boolean\n",
    "\n",
    "    Returns:\n",
    "      Scaled input sequence data.\n",
    "    \"\"\"\n",
    "    t1 = time.time()    \n",
    "    (n_clips, n_time, n_freq, n_channel) = x4d.shape\n",
    "    x4d_scaled = np.zeros(x4d.shape)\n",
    "    for channel in range(n_channel):\n",
    "        x2d = x4d[:,:,:,channel].reshape((n_clips * n_time, n_freq))\n",
    "        x2d_scaled = scaler_list[channel].transform(x2d)\n",
    "        x3d_scaled = x2d_scaled.reshape((n_clips, n_time, n_freq))\n",
    "        x4d_scaled[:,:,:,channel] = x3d_scaled\n",
    "\n",
    "    if verbose == 1:\n",
    "        print(\"Scaling time: %s\" % (time.time() - t1,))\n",
    "\n",
    "    return x4d_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding  fold1 New Features:  (871, 150, 150, 3)\n",
      "Adding  fold2 New Features:  (888, 150, 150, 3)\n",
      "Adding  fold3 New Features:  (925, 150, 150, 3)\n",
      "Adding  fold4 New Features:  (990, 150, 150, 3)\n",
      "Adding  fold5 New Features:  (936, 150, 150, 3)\n",
      "Adding  fold6 New Features:  (823, 150, 150, 3)\n",
      "Adding  fold7 New Features:  (838, 150, 150, 3)\n",
      "Adding  fold8 New Features:  (806, 150, 150, 3)\n",
      "Scaling time: 9.779139757156372\n",
      "Scaling time: 1.1157505512237549\n",
      "Scaling time: 1.2121336460113525\n",
      "(7077, 150, 150, 3)\n",
      "Train on 7077 samples, validate on 816 samples\n",
      "Epoch 1/100\n",
      "7077/7077 [==============================] - 11s 2ms/step - loss: 2.2084 - acc: 0.3380 - val_loss: 2.4649 - val_acc: 0.2868\n",
      "Epoch 2/100\n",
      "7077/7077 [==============================] - 8s 1ms/step - loss: 1.8076 - acc: 0.5025 - val_loss: 2.3382 - val_acc: 0.3211\n",
      "Epoch 3/100\n",
      "5376/7077 [=====================>........] - ETA: 1s - loss: 1.5497 - acc: 0.5943"
     ]
    }
   ],
   "source": [
    "# earlystopping ends training when the validation loss stops improving\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    './sound_classification_epoch_{epoch:03d}_val_loss_{val_loss:.4f}.hdf5',\n",
    "    monitor='val_loss', save_best_only=True)\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_lr=1e-7)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1)\n",
    "callbacks = [reduce_lr_on_plateau, early_stopping]\n",
    "\n",
    "acc_list = []\n",
    "# preliniary estimation of performance\n",
    "\n",
    "# use this if you want to test on 10 folds and obtain standard deviation estimate\n",
    "# for test_fold in range(1, 11):\n",
    "# use this if you just want to test performance on one fold\n",
    "for test_fold in [10]:\n",
    "    keras.backend.clear_session()\n",
    "    model = build_model()\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=Adamax(0.01))\n",
    "\n",
    "    train_x, train_y, valid_x, valid_y, test_x, test_y = load_all_folds(test_fold)\n",
    "\n",
    "    # for each channel, compute scaling factor\n",
    "    scaler_list = []\n",
    "    (n_clips, n_time, n_freq, n_channel) = train_x.shape\n",
    "\n",
    "    for channel in range(n_channel):\n",
    "        t1 = time.time()\n",
    "        xtrain_2d = train_x[:, :, :, channel].reshape((n_clips * n_time, n_freq))\n",
    "        scaler = sklearn.preprocessing.StandardScaler().fit(xtrain_2d)\n",
    "        # print(\"Channel %d Mean: %s\" % (channel, scaler.mean_,))\n",
    "        # print(\"Channel %d Std: %s\" % (channel, scaler.scale_,))\n",
    "        # print(\"Calculating scaler time: %s\" % (time.time() - t1,))\n",
    "        scaler_list += [scaler]\n",
    "\n",
    "    train_x = do_scale(train_x)\n",
    "    valid_x = do_scale(valid_x)\n",
    "    test_x = do_scale(test_x)\n",
    "    \n",
    "    print(train_x.shape)\n",
    "\n",
    "    # use a batch size to fully utilize GPU power\n",
    "    history = model.fit(train_x, train_y, validation_data=(valid_x, valid_y), callbacks=callbacks,\n",
    "                        batch_size=256,\n",
    "                        epochs=100)\n",
    "    acc = evaluate(model, test_x, test_y)\n",
    "\n",
    "    acc_list += [acc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_array = np.array(acc_list)\n",
    "print(\"acc mean %.4f acc std %.4f\" % (acc_array.mean(), acc_array.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#model.fit(train_x, train_y, validation_data=(valid_x, valid_y), callbacks=[earlystop], batch_size=32, nb_epoch=50)\n",
    "acc = evaluate(model, test_x, test_y)  #evaluate(model)\n",
    "\n",
    "labels = [\"air conditioner\", \"horn\", \"children\", \"dog\", \"drill\", \"engine\", \"gun\", \"hammer\", \"siren\", \"music\"]\n",
    "print(\"Showing Confusion Matrix\")\n",
    "y_prob = model.predict(test_x, verbose=0)\n",
    "y_pred = np.argmax(y_prob, axis=-1)\n",
    "y_true = np.argmax(test_y, 1)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
    "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    # Print header\n",
    "    print(\"    \" + empty_cell, end=' ')\n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=' ')\n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % label1, end=' ')\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}s\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=' ')\n",
    "        print()\n",
    "\n",
    "print_cm(cm, labels)\n",
    "\n",
    "df_cm = pd.DataFrame(cm, labels, labels)\n",
    "plt.figure(figsize=(16, 8))\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 14}, fmt='g', linewidths=.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "\n",
    "print(\"History keys:\", (history.history.keys()))\n",
    "# summarise history for training and validation set accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "# summarise history for training and validation set loss\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss', fontsize = 'large')\n",
    "plt.xlabel('epoch', fontsize = 'large' )\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {
    "height": "117px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
