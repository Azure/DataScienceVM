{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Deploy the model\n",
    "\n",
    "In the second notebook we created a basic model and exported it to a file. In this notebook we'll use that same model file to create a REST API with Microsoft ML Server. The Ubuntu DSVM has an installation of ML Server for testing deployments. We'll create a REST API with our model and test it with the same truck image we used in notebook 2 to evaluate the model. \n",
    "\n",
    "There are two variables you must set before running this notebook. The first is the password for your ML Server instance. At MLADS we've already set this for you. If you're following this tutorial on your own, you should configure your ML Server instance for [one-box deployment](https://docs.microsoft.com/en-us/machine-learning-server/operationalize/configure-machine-learning-server-one-box). The second variable is the name of the deployed web service. This needs to be unique on the VM. We recommend that you use your username and a number, like *username5*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a unique service name. We recommend you use your username and a number, like alias3\n",
    "service_name = ____SET_ME_TO_A_UNIQUE_VALUE_____\n",
    "\n",
    "# set the ML Server admin password\n",
    "ml_server_password =  ____SET_ME_____ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.deploy import DeployClient\n",
    "from azureml.deploy.server import MLServer\n",
    "\n",
    "HOST = 'http://localhost:12800'\n",
    "context = ('admin', ml_server_password)\n",
    "client = DeployClient(HOST, use=MLServer, auth=context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the truck image for testing our deployed service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cntk.ai/jup/201/00014.png\" width=\"64\" height=\"64\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow\n",
    "from IPython.display import Image as ImageShow\n",
    "\n",
    "try: \n",
    "    from urllib.request import urlopen \n",
    "except ImportError: \n",
    "    from urllib import urlopen\n",
    "\n",
    "url = \"https://cntk.ai/jup/201/00014.png\"\n",
    "myimg = np.array(Image.open(urlopen(url)), dtype=np.float32)\n",
    "flattened = myimg.ravel()\n",
    "\n",
    "ImageShow(url=url, width=64, height=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cntk\n",
    "\n",
    "with open('model.cntk', mode='rb') as file: # b is important -> binary\n",
    "    binary_model = file.read()\n",
    "\n",
    "# --Define an `init` function to handle service initialization --\n",
    "def init():\n",
    "    import cntk\n",
    "    \n",
    "# define an eval function to handle scoring\n",
    "def eval(image_data):\n",
    "    import numpy as np\n",
    "    import cntk\n",
    "    from pandas import DataFrame\n",
    "    \n",
    "    image_data = image_data.copy().reshape((32, 32, 3))\n",
    "    \n",
    "    image_mean = 133.0\n",
    "    image_data -= image_mean\n",
    "    image_data = np.ascontiguousarray(np.transpose(image_data, (2, 0, 1)))\n",
    "    \n",
    "    loaded_model = cntk.ops.functions.load_model(binary_model)    \n",
    "    results = loaded_model.eval({loaded_model.arguments[0]:[image_data]})\n",
    "        \n",
    "    return DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Txservice12Service in module azureml.deploy.server.service object:\n",
      "\n",
      "class Txservice12Service(Service)\n",
      " |  Service object from metadata.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Txservice12Service\n",
      " |      Service\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, service, http_client)\n",
      " |      Constructor\n",
      " |      \n",
      " |      :param service:\n",
      " |      :param http_client:\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  batch(self, records, parallel_count=10)\n",
      " |      Register a set of input records for batch execution on this service.\n",
      " |      \n",
      " |      :param records: The `data.frame` or `list` of\n",
      " |             input records to execute.\n",
      " |      :param parallel_count: Number of threads used to process entries in\n",
      " |             the batch. Default value is 10. Please make sure not to use too\n",
      " |             high of a number because it might negatively impact performance.\n",
      " |      :return: The `Batch` object to control service batching\n",
      " |              lifecycle.\n",
      " |  \n",
      " |  capabilities(self)\n",
      " |      Gets the service holding capabilities.\n",
      " |      \n",
      " |      :return: A dict of key/values describing the service.\n",
      " |  \n",
      " |  eval(self, image_data)\n",
      " |      Consume the TxService12 service.\n",
      " |      \n",
      " |      My CNTK model\n",
      " |      \n",
      " |      :param numpy.array image_data: The required service input.    \n",
      " |      :returns ServiceResponse: The `<ServiceResponse>` object contains the set of\n",
      " |          expected output values and artifacts. The possible outputs include:\n",
      " |                  \n",
      " |          Output: pandas.DataFrame results        \n",
      " |      \n",
      " |      :Raises:\n",
      " |          HttpException: If server errors occur while executing the service.\n",
      " |          ValueError: If argument input types do not match the expected service\n",
      " |              input types.\n",
      " |  \n",
      " |  get_batch(self, execution_id)\n",
      " |      Retrieve the `Batch` based on an `execution id`\n",
      " |      \n",
      " |      :param execution_id: The id of the batch execution.\n",
      " |      :return: The `Batch`.\n",
      " |  \n",
      " |  list_batch_executions(self)\n",
      " |      Gets all batch executions currently queued for this service.\n",
      " |      \n",
      " |      :return: A list of `execution ids`.\n",
      " |  \n",
      " |  swagger(self)\n",
      " |      Retrieves the `swagger.json` for this service (see http://swagger.io/).\n",
      " |      :return: The swagger document for this service.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'api': '/api/TxService12/1.0',\n",
       " 'artifacts': [],\n",
       " 'creation_time': '2018-05-23T04:14:18.851557',\n",
       " 'description': 'My CNTK model',\n",
       " 'inputs': [{'name': 'image_data', 'type': 'vector'}],\n",
       " 'inputs_encoded': [{'name': 'image_data', 'type': 'numpy.array'}],\n",
       " 'name': 'TxService12',\n",
       " 'operation_id': 'eval',\n",
       " 'outputs': [{'name': 'results', 'type': 'data.frame'}],\n",
       " 'outputs_encoded': [{'name': 'results', 'type': 'pandas.DataFrame'}],\n",
       " 'public-functions': {'batch': 'batch(records, parallel_count=10)',\n",
       "  'capabilities': 'capabilities()',\n",
       "  'eval': 'eval(self,image_data)',\n",
       "  'get_batch': 'get_batch(execution_id)',\n",
       "  'list_batch_execution': 'list_batch_execution()',\n",
       "  'swagger': 'swagger(json=True)'},\n",
       " 'published_by': 'admin',\n",
       " 'runtime': 'Python',\n",
       " 'snapshot_id': '370253b2-1e4a-4007-9890-3eb2b904508e',\n",
       " 'swagger': 'http://localhost:12800/api/TxService12/1.0/swagger.json',\n",
       " 'version': '1.0'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the API\n",
    "service = client.service(service_name)\\\n",
    "        .version('1.0')\\\n",
    "        .code_fn(eval, init)\\\n",
    "        .inputs(image_data=np.array)\\\n",
    "        .outputs(results=pd.DataFrame)\\\n",
    "        .models(binary_model=binary_model)\\\n",
    "        .description('My CNTK model')\\\n",
    "        .deploy()\n",
    "        \n",
    "print(help(service))\n",
    "service.capabilities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now call our newly created API with our truck image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1         2         3         4         5         6  \\\n",
      "0  0.10102  0.115993  0.098485  0.101911  0.093252  0.096514  0.097339   \n",
      "\n",
      "          7        8         9  \n",
      "0  0.099847  0.09435  0.101288  \n",
      "Top 3 predictions:\n",
      "\tLabel: automobile, confidence: 11.60%\n",
      "\tLabel: cat       , confidence: 10.19%\n",
      "\tLabel: truck     , confidence: 10.13%\n",
      "http://localhost:12800/api/TxService12/1.0/swagger.json\n"
     ]
    }
   ],
   "source": [
    "res = service.eval(flattened)\n",
    "\n",
    "# -- Pluck out the named output `results` as defined during publishing and print --\n",
    "print(res.output('results'))\n",
    "\n",
    "# get the top 3 predictions\n",
    "result = res.output('results')\n",
    "result = result.as_matrix()[0]\n",
    "top_count = 3\n",
    "result_indices = (-np.array(result)).argsort()[:top_count]\n",
    "\n",
    "label_lookup = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "print(\"Top 3 predictions:\")\n",
    "for i in range(top_count):\n",
    "    print(\"\\tLabel: {:10s}, confidence: {:.2f}%\".format(label_lookup[result_indices[i]], result[result_indices[i]] * 100))\n",
    "\n",
    "# -- Retrieve the URL of the swagger file for this service.\n",
    "cap = service.capabilities()\n",
    "swagger_URL = cap['swagger']\n",
    "print(swagger_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.swagger())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Microsoft ML Server (Python 3.5)",
   "language": "python",
   "name": "python3-mls"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
