{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure services for Iot\n",
    "\n",
    "## Summary \n",
    "\n",
    "An introduction to the Azure services involved in Iot Development and their respective deployment using the Azure-Python SDK\n",
    "\n",
    "\n",
    "## Description\n",
    "\n",
    "The purpose of this notebook is to give an introduction to the different Azure services that are involved in Iot Solutions, and to deploy them programatically using python and the Azure-SDK.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "* None\n",
    "\n",
    "## Documentation\n",
    "\n",
    "* Resource Groups: https://docs.microsoft.com/en-us/python/api/overview/azure/resources?view=azure-python\n",
    "* Iot Hub: https://docs.microsoft.com/en-us/python/api/overview/azure/iot?view=azure-python\n",
    "* CosmosDB: https://docs.microsoft.com/en-us/python/api/overview/azure/cosmosdb?view=azure-python\n",
    "* Data Lake Store: https://docs.microsoft.com/en-us/python/api/overview/azure/data-lake-store?view=azure-python\n",
    "* Data Lake Analytics: https://docs.microsoft.com/en-us/python/api/overview/azure/data-lake-analytics?view=azure-python\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 2: /usr/bin/az: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "/usr/bin/az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.common.client_factory import get_client_from_cli_profile\n",
    "subscription_id = 'your-subscription-id' ##you cand find this in the portal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resource group\n",
    "\n",
    "First of all we need to set up a resource group in order to store our services.\n",
    "\n",
    "Resource groups provide a way to monitor, control access, provision and manage billing for collections of assets that are required to run an application, or used by a client or company department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Resource Group...\n",
      "Resource Group done\n"
     ]
    }
   ],
   "source": [
    "from azure.mgmt.resource import ResourceManagementClient\n",
    "\n",
    "resource_group = 'resource-group-name' ## Resource group naming \n",
    "location = 'centralus' ## 'eastus2,northeurope,centralus,westeurope', etc..\n",
    "\n",
    "resource_client = get_client_from_cli_profile(ResourceManagementClient)\n",
    "print('Creating Resource Group...')\n",
    "resource_client.resource_groups.create_or_update(resource_group, {'location': location})\n",
    "print('Resource Group done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iot Hub\n",
    "Azure IoT Hub is a fully managed service that enables reliable and secure bidirectional communications between millions of IoT devices and a solution back end. \n",
    "\n",
    "Provides multiple device-to-cloud and cloud-to-device communication options. \n",
    "These options include:\n",
    "* one-way messaging, file transfer, and request-reply methods.\n",
    "* Provides built-in declarative message routing to other Azure services.\n",
    "* Provides a queryable store for device metadata and synchronized state information.\n",
    "* Enables secure communications and access control using per-device security keys or X.509 certificates.\n",
    "* Provides extensive monitoring for device connectivity and device identity management events.\n",
    "* Includes device libraries for the most popular languages and platforms.\n",
    "    \n",
    "IoTHub: Connect, monitor, and manage billions of IoT assets\n",
    "* Establish bi-directional communication with billions of IoT devices\n",
    "* Authenticate per device for security-enhanced IoT solutions\n",
    "* Register devices at scale with IoT Hub Device Provisioning Service\n",
    "* Manage your IoT devices at scale with device management\n",
    "* tend the power of the cloud to your edge device\n",
    "\n",
    "In the next lines we create an Iot hub with default characteristics and a basic SKU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Iot Hub...\n",
      "Iot Hub Done.\n"
     ]
    }
   ],
   "source": [
    "from azure.mgmt.iothub import IotHubClient\n",
    "\n",
    "iot_hub_client = get_client_from_cli_profile(IotHubClient)\n",
    "resouce_name = 'iot-hub-name' \n",
    "location = 'centralus'\n",
    "\n",
    "print('Creating Iot Hub...')\n",
    "iot_hub_client.iot_hub_resource.create_or_update(\n",
    "    resource_group,\n",
    "    resouce_name,\n",
    "    {\n",
    "        'location': location,\n",
    "        'subscriptionid': subscription_id,\n",
    "        'resourcegroup': resource_group,\n",
    "        'sku': {\n",
    "            'name': 'S1',\n",
    "            'capacity': 2\n",
    "        },\n",
    "        'properties': {\n",
    "            'enable_file_upload_notifications': False,\n",
    "            'operations_monitoring_properties': {\n",
    "            'events': {\n",
    "                \"C2DCommands\": \"Error\",\n",
    "                \"DeviceTelemetry\": \"Error\",\n",
    "                \"DeviceIdentityOperations\": \"Error\",\n",
    "                \"Connections\": \"Information\"\n",
    "            }\n",
    "            },\n",
    "            \"features\": \"None\",\n",
    "        }\n",
    "    }\n",
    ").result()\n",
    "\n",
    "print('Iot Hub Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Lake Store\n",
    "\n",
    "Azure Data Lake Store is an enterprise-wide hyper-scale repository for big data analytic workloads. Azure Data Lake enables you to capture data of any size, type, and ingestion speed in one single place for operational and exploratory analytics. Data Lake Store can store trillions of files. A single file can be larger than one petabyte in size. This makes Data Lake Store ideal for storing any type of data including massive datasets like high-resolution video, genomic and seismic datasets, medical data, and data from a wide variety of industries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Data Lake Store...\n",
      "Data Lake Store Done.\n"
     ]
    }
   ],
   "source": [
    "from azure.mgmt.datalake.store import DataLakeStoreAccountManagementClient\n",
    "\n",
    "data_lake_store_client = get_client_from_cli_profile(DataLakeStoreAccountManagementClient)\n",
    "data_lake_store_account = \"Data-Lake-Store-Name\"\n",
    "location = 'centralus'\n",
    "\n",
    "print('Creating Data Lake Store...')\n",
    "data_lake_store_client.account.create(\n",
    "    resource_group,\n",
    "    data_lake_store_account,\n",
    "    {\n",
    "        'location': location\n",
    "    },\n",
    "    None,\n",
    "    False\n",
    ").result()\n",
    "print('Data Lake Store Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Lake Analytics\n",
    "\n",
    "Azure Data Lake Analytics allow us to process big data jobs in seconds. There is no infrastructure to worry about because there are no servers, virtual machines, or clusters to wait for, manage, or tune. We can instantly scale the processing power, measured in Azure Data Lake Analytics Units (AU), from one to thousands for each job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Data Lake Analytics...\n",
      "Data Lake Analytics Done.\n"
     ]
    }
   ],
   "source": [
    "from azure.mgmt.datalake.analytics.account import DataLakeAnalyticsAccountManagementClient\n",
    "from azure.mgmt.datalake.analytics.account.models import DataLakeAnalyticsAccount, DataLakeStoreAccountInfo\n",
    "\n",
    "\n",
    "resource_name = \"Data-Lake-Analytics-Name\"\n",
    "location = 'centralus'\n",
    "data_lake_analytics_client = get_client_from_cli_profile(DataLakeAnalyticsAccountManagementClient)\n",
    "\n",
    "print('Creating Data Lake Analytics...')\n",
    "data_lake_analytics_client.account.create(\n",
    "    resource_group,\n",
    "   resource_name,\n",
    "    DataLakeAnalyticsAccount(\n",
    "        location=location,\n",
    "        default_data_lake_store_account=data_lake_store_account,\n",
    "        data_lake_store_accounts=[DataLakeStoreAccountInfo(name=data_lake_store_account)]\n",
    "    )\n",
    ").result()\n",
    "print('Data Lake Analytics Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosmos DB\n",
    "\n",
    "Cosmos DB is Microsoftâ€™s globally distributed, multi-model database. It supports multiple data models, including but not limited to document, graph, key-value, table, and column-family data models. CosmosDB is able to elastically and independently scale throughput and storage on demand and worldwide\n",
    "\n",
    "CosmosDB provides a solution for doing hot path analytics of our Iot generated data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating CosmosDB...\n",
      "Creating CosmosDB...\n"
     ]
    }
   ],
   "source": [
    "from azure.mgmt.cosmosdb.cosmos_db import CosmosDB\n",
    "from azure.mgmt.cosmosdb.models import Location\n",
    "resource_name = \"CosmosDB-Name\"\n",
    "location = 'centralus'\n",
    "## As stated before  cosmosDB is globally distributed, therefore we can especify\n",
    "## in which regions is it going to be deployed\n",
    "locations = [Location( location_name= 'centralus', failover_priority = 1), Location(location_name= 'eastus', failover_priority = 0)]\n",
    "cosmosdb_client = get_client_from_cli_profile(CosmosDB)\n",
    "\n",
    "\n",
    "print('Creating CosmosDB...')\n",
    "cosmosdb_result = cosmosdb_client.database_accounts.create_or_update(\n",
    "    resource_group,\n",
    "    resource_name,\n",
    "    {\n",
    "        'location' : location,\n",
    "        'locations' : locations,\n",
    "        'kind': 'MongoDB',\n",
    "    }  \n",
    ").result()\n",
    "print('CosmosDB Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if you go into the Azure Portal your services are going to be set up in the resource group that we created in the beginning "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
